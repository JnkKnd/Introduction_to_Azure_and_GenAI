{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本的な RAG を python SDK で構築する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数の設定\n",
    "import requests\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "import io\n",
    "import time\n",
    "import html\n",
    "import jsonpickle\n",
    "import re\n",
    "import base64\n",
    "import glob\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from abc import ABC, abstractclassmethod # 抽象メソッド\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    HnswParameters,\n",
    "    SemanticPrioritizedFields,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    ")\n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryCaptionResult,\n",
    "    QueryAnswerResult,\n",
    "    SemanticErrorMode,\n",
    "    SemanticErrorReason,\n",
    "    SemanticSearchResultsType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorQuery,\n",
    "    VectorFilterMode,    \n",
    ")\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数の設定\n",
    "env_vars = dotenv_values(\".env_rag\")\n",
    "\n",
    "AZURE_OPENAI_KEY = env_vars[\"AZURE_OPENAI_KEY\"]\n",
    "AZURE_OPENAI_ENDPOINT = env_vars[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "DEPLOYMENT_NAME = env_vars[\"DEPLOYMENT_NAME\"]\n",
    "EMBEDDING_MODEL = env_vars[\"EMBEDDING_MODEL\"]\n",
    "\n",
    "AZURE_STORAGE_CONTAINER = env_vars[\"AZURE_STORAGE_CONTAINER\"]\n",
    "AZURE_BLOB_STORAGE_STRING = env_vars[\"AZURE_BLOB_STORAGE_STRING\"]\n",
    "\n",
    "AI_SEARCH_ENDPOINT = env_vars[\"AI_SEARCH_ENDPOINT\"]\n",
    "AI_SEARCH_ADMIN_KEY = env_vars[\"AI_SEARCH_ADMIN_KEY\"]\n",
    "INDEX_NAME = \"index-0321\"\n",
    "AI_SEAERCH_CRED = AzureKeyCredential(AI_SEARCH_ADMIN_KEY)\n",
    "\n",
    "DOCUMENT_INTELLIGENCE_KEY = env_vars[\"DOCUMENT_INTELLIGENCE_KEY\"]\n",
    "DOCUMENT_INTELLIGENCE_ENDPOINT = env_vars[\"DOCUMENT_INTELLIGENCE_ENDPOINT\"]\n",
    "DOCUMENT_INTELLIGENCE_CREDS: str = AzureKeyCredential(DOCUMENT_INTELLIGENCE_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index の作成\n",
    "- Field の設定\n",
    "- セマンティック検索\n",
    "- ベクトル検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Index Schema in Azure AI Search\n",
    "\n",
    "def create_search_index(index_name):\n",
    "    index_client = SearchIndexClient(endpoint=AI_SEARCH_ENDPOINT, credential=AI_SEAERCH_CRED)\n",
    "    if index_name not in index_client.list_index_names():            \n",
    "        index = SearchIndex(\n",
    "            name=index_name,\n",
    "            fields=[\n",
    "                SimpleField(name=\"id\", type=\"Edm.String\", key=True),\n",
    "                SearchableField(\n",
    "                    name=\"content\",\n",
    "                    type=\"Edm.String\",\n",
    "                    analyzer_name=\"ja.lucene\"\n",
    "                ),\n",
    "                SearchField(\n",
    "                    name=\"embedding\",\n",
    "                    type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    hidden=False,\n",
    "                    searchable=True,\n",
    "                    filterable=False,\n",
    "                    sortable=False,\n",
    "                    facetable=False,\n",
    "                    vector_search_dimensions=1536,\n",
    "                    vector_search_configuration=\"default\",\n",
    "                ),\n",
    "                SimpleField(\n",
    "                    name=\"category\",\n",
    "                    type=\"Edm.String\",\n",
    "                    filterable=True,\n",
    "                    facetable=True\n",
    "                ),\n",
    "                SimpleField(\n",
    "                    name=\"sourcepage\",\n",
    "                    type=\"Edm.String\",\n",
    "                    filterable=True,\n",
    "                    facetable=True,\n",
    "                ),\n",
    "                SimpleField(\n",
    "                    name=\"sourcefile\",\n",
    "                    type=\"Edm.String\",\n",
    "                    filterable=True,\n",
    "                    facetable=True,\n",
    "                ),\n",
    "                SimpleField(\n",
    "                    name=\"url\",\n",
    "                    type=\"Edm.String\",\n",
    "                    filterable=True,\n",
    "                    facetable=True,\n",
    "                ),\n",
    "            ],\n",
    "            semantic_settings=SemanticConfiguration(\n",
    "                configurations=[\n",
    "                    SemanticConfiguration(\n",
    "                        name=\"default\",\n",
    "                        prioritized_fields=SemanticPrioritizedFields(\n",
    "                            title_field=None,\n",
    "                            prioritized_content_fields=[\n",
    "                                SemanticField(field_name=\"content\") \n",
    "                            ],\n",
    "                        ),\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            # hnsw, m値, cos類似度\n",
    "            vector_search=VectorSearch(\n",
    "                algorithm_configurations=[\n",
    "                    VectorSearchAlgorithmConfiguration(\n",
    "                        name=\"default\",\n",
    "                        kind=\"hnsw\",\n",
    "                        hnsw_parameters=HnswParameters(\n",
    "                            m = 4,\n",
    "                            ef_construction = 400,\n",
    "                            ef_search = 500,\n",
    "                            metric=\"cosine\"\n",
    "                        ),\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        print(f\"Creating {index_name} search index\")\n",
    "        result = index_client.create_or_update_index(index) \n",
    "        print(f' {result.name} created')\n",
    "    else:\n",
    "        print(f\"Search index {index_name} already exists\")\n",
    "\n",
    "def remove_from_index(filename):\n",
    "    print(f\"Removing sections from '{filename or '<all>'}' from search index '{INDEX_NAME}'\")\n",
    "    search_client = SearchClient(endpoint=AI_SEARCH_ENDPOINT,\n",
    "                                    index_name=INDEX_NAME,\n",
    "                                    credential=AI_SEAERCH_CRED)\n",
    "    while True:\n",
    "        filter = None if filename is None else f\"sourcefile eq '{os.path.basename(filename)}'\"\n",
    "        r = search_client.search(\"\", filter=filter, top=1000, include_total_count=True)\n",
    "        if r.get_count() == 0:\n",
    "            break\n",
    "        r = search_client.delete_documents(documents=[{ \"id\": d[\"id\"] } for d in r])\n",
    "        print(f\"\\tRemoved {len(r)} sections from index\")\n",
    "        # It can take a few seconds for search results to reflect changes, so wait a bit\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ページごとに分割し、Blob Storage にアップロード\n",
    "- PDFの場合は PDFReader を使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in pages and upload to Blob Storage\n",
    "\n",
    "def blob_name_from_file_page(filename, page = 0):\n",
    "    if os.path.splitext(filename)[1].lower() == \".pdf\":\n",
    "        #　ファイル名に空白があったらここ変えればよかったんだな\n",
    "        return os.path.splitext(os.path.basename(filename))[0] + f\"-{page}\" + \".pdf\"\n",
    "    else:\n",
    "        return os.path.basename(filename)\n",
    "\n",
    "def upload_blobs(filename):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(AZURE_BLOB_STORAGE_STRING)\n",
    "    blob_container = blob_service_client.get_container_client(AZURE_STORAGE_CONTAINER)\n",
    "    if not blob_container.exists():\n",
    "        blob_container.create_container()\n",
    "\n",
    "    # ファイルが PDF の場合、ページに分割し、各ページを個別の Blob としてアップロードする。\n",
    "    if os.path.splitext(filename)[1].lower() == \".pdf\":\n",
    "        reader = PdfReader(filename)\n",
    "        pages = reader.pages\n",
    "        for i in range(len(pages)):\n",
    "            blob_name = blob_name_from_file_page(filename, i)\n",
    "            \n",
    "            f = io.BytesIO()\n",
    "            writer = PdfWriter()\n",
    "            writer.add_page(pages[i])\n",
    "            writer.write(f)\n",
    "            f.seek(0)\n",
    "            blob_container.upload_blob(blob_name, f, overwrite=True)\n",
    "    else:\n",
    "        blob_name = blob_name_from_file_page(filename)\n",
    "        # PDF以外は分割せずにUpload\n",
    "        with open(filename,\"rb\") as data:\n",
    "            blob_container.upload_blob(blob_name, data, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Intelligence を用いたテキスト抽出\n",
    "- 表は html に変換して埋め込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Document Intelligence to OCR texts\n",
    "\n",
    "def table_to_html(table):\n",
    "    table_html = \"<table>\"\n",
    "\n",
    "    # 各行のセルに対して、列インデックスに基づいてソート\n",
    "    rows = [sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index) for i in range(table.row_count)]\n",
    "    for row_cells in rows:\n",
    "        table_html += \"<tr>\"\n",
    "        for cell in row_cells:\n",
    "            tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "            cell_spans = \"\"\n",
    "            if cell.column_span > 1: cell_spans += f\" colSpan={cell.column_span}\"\n",
    "            if cell.row_span > 1: cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "            table_html += f\"<{tag}{cell_spans}>{html.escape(cell.content)}</{tag}>\"\n",
    "        table_html +=\"</tr>\"\n",
    "    table_html += \"</table>\"\n",
    "    return table_html\n",
    "\n",
    "def get_document_text(filename):\n",
    "    offset = 0\n",
    "    page_map = []\n",
    "\n",
    "    print(f\"Extracting text from '{filename}' using Azure AI Document Intelligence\")\n",
    "    document_intelligence_client = DocumentAnalysisClient(\n",
    "        endpoint=DOCUMENT_INTELLIGENCE_ENDPOINT,\n",
    "        credential=DOCUMENT_INTELLIGENCE_CREDS, \n",
    "        headers={\"x-ms-useragent\": \"azure-search-chat-demo/1.0.0\"} # user-agent: 識別子\n",
    "        )\n",
    "    with open(filename, \"rb\") as f:\n",
    "        # text 抽出\n",
    "        poller = document_intelligence_client.begin_analyze_document(\"prebuilt-layout\", document = f)\n",
    "    document_intelligence_results = poller.result()\n",
    "    \n",
    "    #　Embed table html in page texts\n",
    "    for page_num, page in enumerate(document_intelligence_results.pages):\n",
    "        tables_on_page = [table for table in document_intelligence_results.tables if table.bounding_regions[0].page_number == page_num + 1]\n",
    "\n",
    "        # mark all positions of the table spans in the page\n",
    "        page_offset = page.spans[0].offset\n",
    "        page_length = page.spans[0].length\n",
    "        table_chars = [-1]*page_length\n",
    "        for table_id, table in enumerate(tables_on_page):\n",
    "            for span in table.spans:\n",
    "                # replace all table spans with \"table_id\" in table_chars array\n",
    "                for i in range(span.length):\n",
    "                    idx = span.offset - page_offset + i\n",
    "                    if idx >=0 and idx < page_length:\n",
    "                        table_chars[idx] = table_id\n",
    "\n",
    "        # build page text by replacing characters in table spans with table html, using table_to_html function\n",
    "        page_text = \"\"\n",
    "        added_tables = set()\n",
    "        for idx, table_id in enumerate(table_chars):\n",
    "            if table_id == -1:\n",
    "                page_text += document_intelligence_results.content[page_offset + idx]\n",
    "            elif table_id not in added_tables:\n",
    "                page_text += table_to_html(tables_on_page[table_id])\n",
    "                added_tables.add(table_id)\n",
    "\n",
    "        page_text += \" \"\n",
    "        page_map.append((page_num, offset, page_text))\n",
    "        offset += len(page_text)\n",
    "\n",
    "    return page_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding\n",
    "- api_version を 2024-02-01 に変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_client = AzureOpenAI(\n",
    "  api_key = AZURE_OPENAI_KEY,  \n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "# Embeddings API のコールにリトライを設定することで Rate limit に対処\n",
    "def before_retry_sleep(retry_state):\n",
    "    print(\"Rate limited on the OpenAI embeddings API, sleeping before retrying...\")\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=15, max=60), stop=stop_after_attempt(15), before_sleep=before_retry_sleep)\n",
    "def compute_embedding(text):\n",
    "    return aoai_client.embeddings.create(input = [text], model=EMBEDDING_MODEL).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### チャンキング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SECTION_LENGTH = 1000\n",
    "SENTENCE_SEARCH_LIMIT = 100\n",
    "SECTION_OVERLAP = 100\n",
    "\n",
    "def split_text(page_map, filename):\n",
    "    SENTENCE_ENDINGS = [\".\", \"!\", \"?\",\"。\"]\n",
    "    WORDS_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\",\"、\", \"\\t\", \"\\n\"]\n",
    "    print(f\"Splitting '{filename}' into sections\")\n",
    "\n",
    "    def find_page(offset):\n",
    "        num_pages = len(page_map)\n",
    "        for i in range(num_pages - 1):\n",
    "            if offset >= page_map[i][1] and offset < page_map[i + 1][1]:\n",
    "                return i\n",
    "        return num_pages - 1\n",
    "\n",
    "    all_text = \"\".join(p[2] for p in page_map)\n",
    "    length = len(all_text)\n",
    "    start = 0\n",
    "    end = length\n",
    "    while start + SECTION_OVERLAP < length: # 全テキストがOverlapより大きい場合\n",
    "        last_word = -1\n",
    "        end = start + MAX_SECTION_LENGTH\n",
    "\n",
    "        if end > length: # 1000文字以内に、全テキストが収まる場合\n",
    "            end = length\n",
    "        else:\n",
    "            # Try to find the end of the sentence\n",
    "            while end < length and (end - start - MAX_SECTION_LENGTH) < SENTENCE_SEARCH_LIMIT and all_text[end] not in SENTENCE_ENDINGS:\n",
    "                if all_text[end] in WORDS_BREAKS:\n",
    "                    last_word = end\n",
    "                end += 1\n",
    "            if end < length and all_text[end] not in SENTENCE_ENDINGS and last_word > 0: # 文の終わりが見つかった場合\n",
    "                end = last_word # Fall back to at least keeping a whole word\n",
    "        if end < length: # 終了位置が見つからなけらば 1000文字から1字ずつ増やす\n",
    "            end += 1\n",
    "\n",
    "        # Try to find the start of the sentence or at least a whole word boundary\n",
    "        last_word = -1\n",
    "        while start > 0 and start > end - MAX_SECTION_LENGTH - 2 * SENTENCE_SEARCH_LIMIT and all_text[start] not in SENTENCE_ENDINGS:\n",
    "            if all_text[start] in WORDS_BREAKS:\n",
    "                last_word = start\n",
    "            start -= 1\n",
    "        if all_text[start] not in SENTENCE_ENDINGS and last_word > 0:\n",
    "            start = last_word\n",
    "        if start > 0:\n",
    "            start += 1\n",
    "\n",
    "        section_text = all_text[start:end]\n",
    "        yield (section_text, find_page(start))\n",
    "\n",
    "        last_table_start = section_text.rfind(\"<table\")\n",
    "        if (last_table_start > 2 * SENTENCE_SEARCH_LIMIT and last_table_start > section_text.rfind(\"</table\")):\n",
    "            # If the section ends with an unclosed table, we need to start the next section with the table.\n",
    "            # If table starts inside SENTENCE_SEARCH_LIMIT, we ignore it, as that will cause an infinite loop for tables longer than MAX_SECTION_LENGTH\n",
    "            # If last table starts inside SECTION_OVERLAP, keep overlapping\n",
    "            print(f\"Section ends with unclosed table, starting next section with the table at page {find_page(start)} offset {start} table start {last_table_start}\")\n",
    "            start = min(end - SECTION_OVERLAP, start + last_table_start)\n",
    "        else:\n",
    "            start = end - SECTION_OVERLAP\n",
    "\n",
    "    if start + SECTION_OVERLAP < end:\n",
    "        yield (all_text[start:end], find_page(start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index に登録するデータのマッピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_to_id(filename):\n",
    "    filename_ascii = re.sub(\"[^0-9a-zA-Z_-]\", \"_\", filename)\n",
    "    filename_hash = base64.b16encode(filename.encode('utf-8')).decode('ascii')\n",
    "    return f\"file-{filename_ascii}-{filename_hash}\"\n",
    "\n",
    "def create_sections(filename, page_map, use_vectors, category):\n",
    "    file_id = filename_to_id(filename)\n",
    "    for i, (content, pagenum) in enumerate(split_text(page_map, filename)):\n",
    "        section = {\n",
    "            \"id\": f\"{file_id}-page-{i}\",\n",
    "            \"content\": content,\n",
    "            \"category\": category,\n",
    "            \"sourcepage\": blob_name_from_file_page(filename, pagenum),\n",
    "            \"sourcefile\": filename,\n",
    "            \"url\": filename, # 要実装、webサイトのadd your data は html でBlobに保存して、metadata_storage_sas_token でアクセス\n",
    "            #\"metadata\": json.dumps({\"page\": pagenum, \"sourcepage\": blob_name_from_file_page(filename, pagenum)})\n",
    "        }\n",
    "        \n",
    "        section[\"embedding\"] = compute_embedding(content) # Embedding 計算結果\n",
    "        yield section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### チャンクをインデックス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_sections(filename, sections):\n",
    "    search_client = SearchClient(\n",
    "        endpoint=AI_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=AI_SEAERCH_CRED\n",
    "    )\n",
    "    i = 0\n",
    "    batch = []\n",
    "    for s in sections:\n",
    "        batch.append(s)\n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            results = search_client.upload_documents(documents=batch)\n",
    "            succeeded = sum([1 for r in results if r.succeeded])\n",
    "            print(f\"\\tIndexed {len(results)} sections, {succeeded} succeeded\")\n",
    "            batch = []\n",
    "\n",
    "    if len(batch) > 0:\n",
    "        results = search_client.upload_documents(documents=batch)\n",
    "        succeeded = sum([1 for r in results if r.succeeded])\n",
    "        print(f\"\\tIndexed {len(results)} sections, {succeeded} succeeded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 実行部分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Search Index...\n",
      "Search index index-0321 already exists\n",
      "Processing files...\n",
      "Processing './sampledata/text\\Contoso_Estate_Support_Guide.pdf'\n",
      "Removing sections from './sampledata/text\\Contoso_Estate_Support_Guide.pdf' from search index 'index-0321'\n",
      "\tRemoved 6 sections from index\n",
      "Extracting text from './sampledata/text\\Contoso_Estate_Support_Guide.pdf' using Azure AI Document Intelligence\n",
      "Splitting 'Contoso_Estate_Support_Guide.pdf' into sections\n",
      "\tIndexed 6 sections, 6 succeeded\n",
      "Processing './sampledata/text\\model-work-regulations.pdf'\n",
      "Removing sections from './sampledata/text\\model-work-regulations.pdf' from search index 'index-0321'\n",
      "\tRemoved 95 sections from index\n",
      "Extracting text from './sampledata/text\\model-work-regulations.pdf' using Azure AI Document Intelligence\n",
      "Splitting 'model-work-regulations.pdf' into sections\n",
      "Section ends with unclosed table, starting next section with the table at page 0 offset 0 table start 794\n",
      "Section ends with unclosed table, starting next section with the table at page 11 offset 7435 table start 952\n",
      "Section ends with unclosed table, starting next section with the table at page 25 offset 19649 table start 788\n",
      "Section ends with unclosed table, starting next section with the table at page 30 offset 26099 table start 1105\n",
      "Section ends with unclosed table, starting next section with the table at page 32 offset 28092 table start 826\n",
      "Section ends with unclosed table, starting next section with the table at page 32 offset 28822 table start 1116\n",
      "Section ends with unclosed table, starting next section with the table at page 32 offset 29820 table start 798\n",
      "Section ends with unclosed table, starting next section with the table at page 32 offset 30521 table start 620\n",
      "Section ends with unclosed table, starting next section with the table at page 32 offset 31137 table start 599\n",
      "Section ends with unclosed table, starting next section with the table at page 32 offset 31728 table start 1066\n",
      "Section ends with unclosed table, starting next section with the table at page 32 offset 32634 table start 876\n",
      "Section ends with unclosed table, starting next section with the table at page 35 offset 38067 table start 1041\n",
      "Section ends with unclosed table, starting next section with the table at page 37 offset 39107 table start 398\n",
      "Section ends with unclosed table, starting next section with the table at page 47 offset 48891 table start 861\n",
      "\tIndexed 95 sections, 95 succeeded\n"
     ]
    }
   ],
   "source": [
    "print(\"Create Search Index...\")\n",
    "create_search_index(INDEX_NAME)\n",
    "print(\"Processing files...\")\n",
    "\n",
    "path_pattern = \"./sampledata/text/*.pdf\"\n",
    "for filename in glob.glob(path_pattern):\n",
    "    print(f\"Processing '{filename}'\")\n",
    "    try:\n",
    "        upload_blobs(filename)\n",
    "        remove_from_index(filename)\n",
    "        page_map = get_document_text(filename)\n",
    "        category = os.path.basename(os.path.dirname(filename)) # 親ディレクトリ名\n",
    "        sections = create_sections(\n",
    "            os.path.basename(filename), page_map, False, category\n",
    "        )\n",
    "        index_sections(os.path.basename(filename), sections)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\tGot an error while reading {filename} -> {e} --> skipping file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### これで Index 作成完了！\n",
    "#### セマンティックハイブリッド検索を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semantic answer =  []\n",
      "Caption: 検索·予約方法は以下の通りです。 賃貸物件の検索と予約方法をご紹介します: 1. 賃貸物件を検索する: - 目的地、チェックイン日、チェックアウト日、宿泊人数を入力します。 - 価格帯、物件タイプ、アメニティなどのフィルターを適用して選択肢を絞り込む。 - リストを閲覧して、滞在に最適な場所を見つけましょう。 2. リスティングの詳細を見る: - リスティングをクリックすると、写真、物件概要、レビュー、ホスト情報などの詳 細情報が表示されます、 およびホスト情報を含む詳細情報を表示します。 .\u0000\n",
      "\n",
      "Caption: 方法は以下の通りです: 1. ログインする: - Contoso<em> Real Estate</em> アカウントにログインします。 2. あなたの予約」に進みます: - プロフィール画像をクリックし、\"予約状況 \"に移動します。 3. 問題のある予約を選択します: - 問題のあるリスティングに関連付けられている予約を見つけてクリックします。 4. 問題を報告する: - 問題を報告する」ボタンをクリックします。 - リスティングで発生した問題を詳しく説明してください。 5. レポートを提出する: - 必要な情報を提供したら、レポートを送信してください。 当社のチームが問題を調査し、適切な処置を講じます。 5.\n",
      "\n",
      "Caption: ここではその方法を説明します: 1. ログインする: - Contoso<em> Real Estate</em> アカウントにログインします。 2. あなたの予約」に移動します: - プロフィール画像をクリックし、\"予約状況\"に移動します。 3. キャンセルする予約を選択します: - キャンセルしたい予約を見つけてクリックします。 4. 予約をキャンセルする: - 予約をキャンセルする」ボタンをクリックします。 - キャンセルポリシーを確認し、手数料の可能性を理解する。 - キャンセルを確認します。 5. キャンセル料: - ホストのキャンセルポリシーによっては、キャンセル料が発生する場合がありま す。 キャンセル料 キャンセルの手続き中に明確に表示されます。 6.\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "user_query = \"賃貸物件の予約方法について教えてください。\"\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# タイトルフィールドとコンテンツフィールドのEmbeddingsを生成する関数\n",
    "def embed_user_query(text, model = EMBEDDING_MODEL):\n",
    "    return aoai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "vector_query = VectorizedQuery(vector=embed_user_query(user_query), k_nearest_neighbors=50, fields=\"embedding\")\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=AI_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=AI_SEAERCH_CRED\n",
    ")\n",
    "\n",
    "retrieved_docs = search_client.search(\n",
    "    search_text = user_query,\n",
    "    vector_queries= [vector_query],\n",
    "    top=3,\n",
    "    highlight_fields=\"content-3\",\n",
    "    select=[\"sourcepage\",\"content\",\"category\"],\n",
    "    query_type=QueryType.SEMANTIC, \n",
    "    semantic_configuration_name='default', \n",
    "    query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    ")\n",
    "\n",
    "semantic_answers = retrieved_docs.get_answers()\n",
    "print('semantic answer = ',semantic_answers)\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "    \n",
    "for doc in retrieved_docs:\n",
    "    # print(f\"Source: {doc['sourcepage']}\")  \n",
    "    # print(f\"Score: {doc['@search.score']}\")  \n",
    "    #print(f\"Content: {doc['content']}\")  \n",
    "    # print(f\"Category: {doc['category']}\\n\")\n",
    "    \n",
    "    captions = doc[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n",
    "\n",
    "# 改行や括弧を変換\n",
    "def nonewlines(s: str) -> str:\n",
    "    return s.replace('\\n', ' ').replace('\\r', ' ').replace('[', '【').replace(']', '】')\n",
    "\n",
    "results =[\" SOURCE:\" + doc['sourcepage'] + \": \" + nonewlines(doc['content']) for doc in retrieved_docs]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '\\n以下は、過去の会話の履歴と、Contoso Estate という会社の文書を検索して回答する必要のあるユーザーからの新しい質問です。\\n会話と新しい質問に基づいて、検索クエリを作成してください。\\n検索クエリには、引用されたファイルや文書の名前（例:info.txtやdoc.pdf)を含めないでください。\\n検索クエリには、括弧 []または<<>>内のテキストを含めないでください。\\n検索クエリを生成できない場合は、数字 0 だけを返してください。\\n'}, {'role': 'user', 'content': '予約のキャンセル方法についての手順をおしえてください'}, {'role': 'assistant', 'content': '予約 キャンセル 方法'}, {'role': 'user', 'content': '問い合わせ先の情報を教えてください'}, {'role': 'assistant', 'content': 'お問い合わせ 連絡先'}, {'role': 'user', 'content': '賃貸物件の予約方法について教えてください。'}]\n",
      "生成されたクエリ： 賃貸物件 予約 方法\n"
     ]
    }
   ],
   "source": [
    "query_generation_prompt = \"\"\"\n",
    "以下は、過去の会話の履歴と、Contoso Estate という会社の文書を検索して回答する必要のあるユーザーからの新しい質問です。\n",
    "会話と新しい質問に基づいて、検索クエリを作成してください。\n",
    "検索クエリには、引用されたファイルや文書の名前（例:info.txtやdoc.pdf)を含めないでください。\n",
    "検索クエリには、括弧 []または<<>>内のテキストを含めないでください。\n",
    "検索クエリを生成できない場合は、数字 0 だけを返してください。\n",
    "\"\"\"\n",
    "\n",
    "prompt = [{'role': 'system', 'content': query_generation_prompt}]\n",
    "\n",
    "# Few-shot Samples\n",
    "query_prompt_few_shots = [\n",
    "    {'role' : 'user', 'content' : '予約のキャンセル方法についての手順をおしえてください' },\n",
    "    {'role' : 'assistant', 'content' : '予約 キャンセル 方法' },\n",
    "    {'role' : 'user', 'content' : '問い合わせ先の情報を教えてください' },\n",
    "    {'role' : 'assistant', 'content' : 'お問い合わせ 連絡先' }\n",
    "]\n",
    "\n",
    "for shot in query_prompt_few_shots:\n",
    "    prompt.append({'role': shot.get('role'), 'content': shot.get('content')})\n",
    "\n",
    "prompt.append({'role': 'user', 'content': user_query})\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "chat_completion = aoai_client.chat.completions.create(\n",
    "    messages=prompt,\n",
    "    model=DEPLOYMENT_NAME,\n",
    "    temperature=0.0,\n",
    "    max_tokens=100,\n",
    "    n=1)\n",
    "\n",
    "query_text = chat_completion.choices[0].message.content\n",
    "print('生成されたクエリ：',query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "あなたは Contoso Estate のカスタマーサポートとして、ユーザーからの問いに丁寧に答えます。\n",
    "出典から答えが推測できない場合は「わからない」と答えること。\n",
    "回答は日本語で生成しなさい。\n",
    "\n",
    "# 制限事項\n",
    "- 回答で使用される事実は、その出典を回答の最後に含まなければならない。\n",
    "- 出典を参照するには角括弧を使用する。例えば、[info1.txt]。出典を結合せず、各出典を個別に記載すること。例：[info1.txt][info2.pdf]。\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role': 'system', 'content': system_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contoso Estateの賃貸物件の予約方法については、以下の手順に従って予約することができます。\n",
      "\n",
      "1. Contoso Estateのウェブサイトにアクセスします。\n",
      "2. メニューから「賃貸物件」を選択します。\n",
      "3. 検索フォームに希望する条件（地域、家賃、間取りなど）を入力し、検索ボタンをクリックします。\n",
      "4. 検索結果から予約したい物件を選択します。\n",
      "5. 物件の詳細ページで、予約ボタンをクリックします。\n",
      "6. 予約フォームに必要事項（氏名、連絡先、予約期間など）を入力し、送信ボタンをクリックします。\n",
      "7. Contoso Estateの担当者から予約の確認や支払い方法についての連絡があります。\n",
      "\n",
      "以上がContoso Estateの賃貸物件の予約方法です。詳細や特定の物件に関する情報は、Contoso Estateのウェブサイトをご確認ください。\n",
      "\n",
      "[info1.txt]\n"
     ]
    }
   ],
   "source": [
    "# Context from Azure AI Search\n",
    "context = \"\\n\".join(results)\n",
    "messages.append({'role': 'user', 'content': user_query + \"\\n\\n\" + context}) \n",
    "\n",
    "chat_coroutine = aoai_client.chat.completions.create(\n",
    "    model=DEPLOYMENT_NAME,\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(chat_coroutine.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "key = \"07a02365e5fd45bc97fa4646b152d840\"\n",
    "base = \"https://aoai-japaneast-jk.openai.azure.com/\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=key,  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=base\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.028185436502099037, 0.0029579917900264263, -0.01179675292223692, -0.0010546649573370814, 0.0029527097940444946]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = \"text-embedding-ada-002-jk\"\n",
    "def get_embedding(text):\n",
    "    result = client.embeddings.create(\n",
    "      model=embedding_model,\n",
    "      input=text\n",
    "    )\n",
    "    result = result.data[0].embedding\n",
    "    return result\n",
    "\n",
    "test = get_embedding(\"Testing embedding function\")\n",
    "print(test[0:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
